{
  "hash": "dd440e55682ee6b10d1917b8c7068fe7",
  "result": {
    "markdown": "---\ntitle: Classification\nauthor: Tahmina Sultana\ndate: '2023-11-24'\ncategories:\n  - python\n  - code\n  - analysis\nimage: img1.webp\ndescription: 'Classification in Machine Learning involves the process of assigning predefined categories or labels to data points based on their features, enabling algorithms to learn and predict the class of new, unseen instances.'\n---\n\n![Machine Learning Algorithms for Classification (src: <https://towardsdatascience.com/top-machine-learning-algorithms-for-classification-2197870ff501>)](img.webp){fig-alt=\"Machine Learning Algorithms for Classification (src: https://towardsdatascience.com/top-machine-learning-algorithms-for-classification-2197870ff501)\"}\n\n**Contents:**\n\n-   Introduction to Classification.\n\n-   Different types of classification.\n\n-   Example of Linear Regression with [Heart Failure Prediction dataset](https://www.kaggle.com/code/ratndeepchavan/prediction-of-heart-failure/input?select=heart.csv).\n\n-   Data Visualization\n\n-   Data processing\n\n-   Model implementation\n\n-   Evaluation metrics implementation\n\n## Introduction to Classification\n\nIn the dynamic world of machine learning, classification stands out as a pivotal concept, providing the ability to categorize and interpret data for a wide array of applications. Whether you're looking to filter spam emails, identify diseases from medical data, or recognize handwritten digits, classification algorithms are your go-to tools. In this blog post, we'll delve into what classification is in machine learning, its significance, and how it's transforming industries.\n\n## Defining Classification in Machine Learning\n\nAt its core, classification is the process of recognizing, understanding, and grouping data into predefined categories or subgroups. It's like having a smart assistant that can look at a new piece of data and tell you which group it belongs to based on its characteristics. This task is accomplished through the analysis of historical data, which serves as a training ground for machine learning models.\n\n## The Power of Predefined Categories\n\nThe magic of classification lies in these predefined categories. Think of them as labels, such as \"spam\" and \"non-spam\" for emails, \"fraudulent\" and \"legitimate\" for financial transactions, or \"cat\" and \"dog\" for image recognition. The ability to organize data into these categories enables decision-making, automation, and insights that would otherwise be impractical or impossible to achieve manually.\n\n## How Classification Works\n\nTo perform classification, machine learning algorithms need to learn from data first. This \"training\" phase involves feeding the algorithm a labeled dataset, where each data point is associated with the category it belongs to. The algorithm then learns the patterns, relationships, and features that characterize each category.\n\nOnce trained, the algorithm can classify new, unseen data by assessing its similarity to the patterns it has learned. It predicts the likelihood of the new data point falling into one of the predefined categories. This process is akin to your email provider recognizing whether an incoming email is spam or not based on past experiences.\n\n## Real-Life Applications\n\nClassification has found its way into countless real-world applications. From medical diagnoses to recommendation systems, here are a few examples:\n\n-   **Medical Diagnoses**: Doctors use machine learning models to predict whether a patient has a particular disease based on symptoms, medical history, and test results.\n\n-   **Recommendation Systems**: Companies like Netflix and Amazon employ classification to recommend movies or products to users based on their preferences and behavior.\n\n-   **Sentiment Analysis**: Social media platforms analyze posts to classify them as positive, negative, or neutral, providing valuable insights into public opinion.\n\n-   **Image Recognition**: In the field of computer vision, classification helps identify objects, animals, or handwritten text in images.\n\n### Popular Classification Algorithms:\n\n-   [Logistic Regression](https://monkeylearn.com/blog/classification-algorithms/#logistic-regression): Logistic regression is a widely used classification algorithm that models the probability of an input belonging to a particular category. It's simple, interpretable, and effective for binary and multiclass classification tasks.\n\n-   [Naive Bayes](https://monkeylearn.com/blog/classification-algorithms/#naive-bayes): Naive Bayes is a probabilistic classification algorithm based on Bayes' theorem. It's particularly suited for text classification tasks and spam email filtering, where it assumes independence between features.\n\n-   [K-Nearest Neighbors](https://monkeylearn.com/blog/classification-algorithms/#knn): K-NN is a straightforward yet powerful algorithm that classifies data points based on the majority class among their k-nearest neighbors. It's versatile and can be applied to various types of data, but the choice of k is crucial for its performance.\n\n-   [Decision Tree](https://monkeylearn.com/blog/classification-algorithms/#decision-tree): Decision tree classifiers make decisions by splitting data based on features, creating a tree-like structure of decisions. They are interpretable and can handle both categorical and numerical data, making them useful in many applications.\n\n-   [Support Vector Machines](https://monkeylearn.com/blog/classification-algorithms/#svm): SVMs are effective for both linear and nonlinear classification tasks. They work by finding the optimal hyperplane that maximizes the margin between classes, making them robust against overfitting and suitable for high-dimensional data.\n\n## Example: Heart Disease Prediction\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd \nimport numpy as np \nimport seaborn as sns \nimport matplotlib.pyplot as plt \nfrom sklearn.metrics import roc_curve, precision_recall_curve\nfrom sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, f1_score, accuracy_score\nfrom sklearn.metrics import make_scorer, precision_score, precision_recall_curve\nfrom sklearn.metrics import recall_score\nfrom sklearn.preprocessing import StandardScaler\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n```\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nsns.set_theme(context='notebook',\n              style='white',\n              palette='deep',\n              font_scale=1.5,\n              color_codes=True,\n              rc=None)\n\nimport matplotlib\n\nplt.rcParams['figure.figsize'] = (14,8) \nplt.rcParams['figure.facecolor'] = '#F0F8FF'\nplt.rcParams['figure.titlesize'] = 'medium'\nplt.rcParams['figure.dpi'] = 100\nplt.rcParams['figure.edgecolor'] = 'green'\nplt.rcParams['figure.frameon'] = True\n\nplt.rcParams[\"figure.autolayout\"] = True\n\nplt.rcParams['axes.facecolor'] = '#F5F5DC'\nplt.rcParams['axes.titlesize'] = 25   \nplt.rcParams[\"axes.titleweight\"] = 'normal'\nplt.rcParams[\"axes.titlecolor\"] = 'Olive'\nplt.rcParams['axes.edgecolor'] = 'pink'\nplt.rcParams[\"axes.linewidth\"] = 2\nplt.rcParams[\"axes.grid\"] = True\nplt.rcParams['axes.titlelocation'] = 'center' \nplt.rcParams[\"axes.labelsize\"] = 20\nplt.rcParams[\"axes.labelpad\"] = 2\nplt.rcParams['axes.labelweight'] = 1\nplt.rcParams[\"axes.labelcolor\"] = 'Olive'\nplt.rcParams[\"axes.axisbelow\"] = False \nplt.rcParams['axes.xmargin'] = .2\nplt.rcParams[\"axes.ymargin\"] = .2\n\n\nplt.rcParams[\"xtick.bottom\"] = True \nplt.rcParams['xtick.color'] = '#A52A2A'\nplt.rcParams[\"ytick.left\"] = True  \nplt.rcParams['ytick.color'] = '#A52A2A'\n\nplt.rcParams['axes.grid'] = True \nplt.rcParams['grid.color'] = 'green'\nplt.rcParams['grid.linestyle'] = '--' \nplt.rcParams['grid.linewidth'] = .5\nplt.rcParams['grid.alpha'] = .3       \n\nplt.rcParams['legend.loc'] = 'best' \nplt.rcParams['legend.facecolor'] =  'NavajoWhite'  \nplt.rcParams['legend.edgecolor'] = 'pink'\nplt.rcParams['legend.shadow'] = True\nplt.rcParams['legend.fontsize'] = 20\n\nplt.rcParams['font.size'] = 14\n\nplt.rcParams['figure.dpi'] = 200\nplt.rcParams['figure.edgecolor'] = 'Blue'\n```\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\npd.set_option('display.max_columns',None)\npd.set_option('display.max_rows',None)\npd.set_option(\"display.precision\", 2)\n```\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nheart1 = pd.read_csv('/home/tpriya/CS5525/MLBlog/posts/classification/heart.csv')\nheart1.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>ChestPainType</th>\n      <th>RestingBP</th>\n      <th>Cholesterol</th>\n      <th>FastingBS</th>\n      <th>RestingECG</th>\n      <th>MaxHR</th>\n      <th>ExerciseAngina</th>\n      <th>Oldpeak</th>\n      <th>ST_Slope</th>\n      <th>HeartDisease</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40</td>\n      <td>M</td>\n      <td>ATA</td>\n      <td>140</td>\n      <td>289</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>172</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49</td>\n      <td>F</td>\n      <td>NAP</td>\n      <td>160</td>\n      <td>180</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>156</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>Flat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37</td>\n      <td>M</td>\n      <td>ATA</td>\n      <td>130</td>\n      <td>283</td>\n      <td>0</td>\n      <td>ST</td>\n      <td>98</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48</td>\n      <td>F</td>\n      <td>ASY</td>\n      <td>138</td>\n      <td>214</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>108</td>\n      <td>Y</td>\n      <td>1.5</td>\n      <td>Flat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54</td>\n      <td>M</td>\n      <td>NAP</td>\n      <td>150</td>\n      <td>195</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>122</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n**Attributes:**\n\n-   **Age:** Age of the patient \\[years\\]\n\n-   **Sex:** Sex of the patient \\[M: Male, F: Female\\]\n\n-   **ChestPainType:** Chest Pain Type \\[TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal Pain, ASY: Asymptomatic\\]\n\n-   **RestingBP:** Resting blood pressure \\[mm Hg\\]\n\n-   **Cholesterol:** Serum cholesterol \\[mm/dl\\]\n\n-   **FastingBS:** Fasting blood sugar \\[1: if FastingBS \\> 120 mg/dl, 0: otherwise\\]\n\n-   **RestingECG**: Resting electrocardiogram results \\[Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of \\> 0.05 mV), LVH: showing probable or definite left ventricular hypertrophy by Estes' criteria\\]\n\n-   **MaxHR:** Maximum heart rate achieved \\[Numeric value between 60 and 202\\]\n\n-   **ExerciseAngina:** Exercise-induced angina \\[Y: Yes, N: No\\]\n\n-   **Oldpeak:** Oldpeak = ST \\[Numeric value measured in depression\\]\n\n-   **ST_Slope:** The slope of the peak exercise ST segment \\[Up: upsloping, Flat: flat, Down: downsloping\\]\n\n-   **HeartDisease:** Output class \\[1: heart disease, 0: Normal\\]\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nheart1.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 918 entries, 0 to 917\nData columns (total 12 columns):\n #   Column          Non-Null Count  Dtype  \n---  ------          --------------  -----  \n 0   Age             918 non-null    int64  \n 1   Sex             918 non-null    object \n 2   ChestPainType   918 non-null    object \n 3   RestingBP       918 non-null    int64  \n 4   Cholesterol     918 non-null    int64  \n 5   FastingBS       918 non-null    int64  \n 6   RestingECG      918 non-null    object \n 7   MaxHR           918 non-null    int64  \n 8   ExerciseAngina  918 non-null    object \n 9   Oldpeak         918 non-null    float64\n 10  ST_Slope        918 non-null    object \n 11  HeartDisease    918 non-null    int64  \ndtypes: float64(1), int64(6), object(5)\nmemory usage: 86.2+ KB\n```\n:::\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nheart1.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>RestingBP</th>\n      <th>Cholesterol</th>\n      <th>FastingBS</th>\n      <th>MaxHR</th>\n      <th>Oldpeak</th>\n      <th>HeartDisease</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>918.00</td>\n      <td>918.00</td>\n      <td>918.00</td>\n      <td>918.00</td>\n      <td>918.00</td>\n      <td>918.00</td>\n      <td>918.00</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>53.51</td>\n      <td>132.40</td>\n      <td>198.80</td>\n      <td>0.23</td>\n      <td>136.81</td>\n      <td>0.89</td>\n      <td>0.55</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>9.43</td>\n      <td>18.51</td>\n      <td>109.38</td>\n      <td>0.42</td>\n      <td>25.46</td>\n      <td>1.07</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>28.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>60.00</td>\n      <td>-2.60</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>47.00</td>\n      <td>120.00</td>\n      <td>173.25</td>\n      <td>0.00</td>\n      <td>120.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>54.00</td>\n      <td>130.00</td>\n      <td>223.00</td>\n      <td>0.00</td>\n      <td>138.00</td>\n      <td>0.60</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>60.00</td>\n      <td>140.00</td>\n      <td>267.00</td>\n      <td>0.00</td>\n      <td>156.00</td>\n      <td>1.50</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>77.00</td>\n      <td>200.00</td>\n      <td>603.00</td>\n      <td>1.00</td>\n      <td>202.00</td>\n      <td>6.20</td>\n      <td>1.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nheart1.isnull().mean()*100\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\nAge               0.0\nSex               0.0\nChestPainType     0.0\nRestingBP         0.0\nCholesterol       0.0\nFastingBS         0.0\nRestingECG        0.0\nMaxHR             0.0\nExerciseAngina    0.0\nOldpeak           0.0\nST_Slope          0.0\nHeartDisease      0.0\ndtype: float64\n```\n:::\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nWomen = heart1.loc[heart1['Sex'] == 'F'][\"HeartDisease\"]\nrate_women = (Women.sum()/len(Women)).round(2)*100\nprint(\"Percentage of Women with probability of HeartDisease:\", rate_women,\"%\")\n\nMen = heart1.loc[heart1['Sex'] == 'M'][\"HeartDisease\"]\nrate_men = (Men.sum()/len(Men)).round(2)*100\nprint(\"Percentage of Men with probability of HeartDisease  :\", rate_men,\"%\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPercentage of Women with probability of HeartDisease: 26.0 %\nPercentage of Men with probability of HeartDisease  : 63.0 %\n```\n:::\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nprint(f'We have {heart1.shape[0]} instances with the {heart1.shape[1]-1} features and 1 output variable')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe have 918 instances with the 11 features and 1 output variable\n```\n:::\n:::\n\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\n## Combining Data\nheart1.agg(\n    {\n       \"Age\": [\"min\", \"max\", \"median\",\"mean\", \"skew\", 'std'],\n        \"RestingBP\": [\"min\", \"max\", \"median\", \"mean\",\"skew\",'std'],\n        \"Cholesterol\": [\"min\", \"max\", \"median\", \"mean\",\"skew\",'std'],\n        \"Oldpeak\": [\"min\", \"max\", \"median\", \"mean\",\"skew\",'std'],\n        \"MaxHR\": [\"min\", \"max\", \"median\", \"mean\",\"skew\",'std']\n    }\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>RestingBP</th>\n      <th>Cholesterol</th>\n      <th>Oldpeak</th>\n      <th>MaxHR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>min</th>\n      <td>28.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>-2.60</td>\n      <td>60.00</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>77.00</td>\n      <td>200.00</td>\n      <td>603.00</td>\n      <td>6.20</td>\n      <td>202.00</td>\n    </tr>\n    <tr>\n      <th>median</th>\n      <td>54.00</td>\n      <td>130.00</td>\n      <td>223.00</td>\n      <td>0.60</td>\n      <td>138.00</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>53.51</td>\n      <td>132.40</td>\n      <td>198.80</td>\n      <td>0.89</td>\n      <td>136.81</td>\n    </tr>\n    <tr>\n      <th>skew</th>\n      <td>-0.20</td>\n      <td>0.18</td>\n      <td>-0.61</td>\n      <td>1.02</td>\n      <td>-0.14</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>9.43</td>\n      <td>18.51</td>\n      <td>109.38</td>\n      <td>1.07</td>\n      <td>25.46</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nsns.kdeplot( data=heart1, x=\"Cholesterol\", hue=\"ChestPainType\", fill=True, common_norm=False, palette=\"tab10\", alpha=.5, linewidth=0);\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-12-output-1.png){}\n:::\n:::\n\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nsns.displot(data=heart1, x=\"Cholesterol\", hue=\"ChestPainType\", col=\"Sex\", kind=\"kde\");\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-1.png){}\n:::\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nheart1.nunique().plot(kind='bar')\nplt.title('No of unique values in the dataset')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-14-output-1.png){}\n:::\n:::\n\n\n**Outliers in Data**\n\nOutliers represent atypical data points that have the potential to disrupt statistical analyses and challenge their underlying assumptions. Dealing with outliers is a common task for analysts, and deciding how to handle them can be a complex process. While the instinct may be to eliminate outliers to mitigate their impact, this approach is appropriate only in certain circumstances and should not be the default choice\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nplt.figure(figsize=(14,20))\nplt.subplot(5,2,1)\nsns.distplot(heart1['Age'],color='DeepPink')\nplt.subplot(5,2,2)\nsns.boxplot(heart1['Age'],color='DeepPink')\nplt.subplot(5,2,3)\nsns.distplot(heart1['RestingBP'],color='DarkSlateGray')\nplt.subplot(5,2,4)\nsns.boxplot(heart1['RestingBP'],color='DarkSlateGray')\nplt.subplot(5,2,5)\nsns.distplot(heart1['Cholesterol'],color='Green')\nplt.subplot(5,2,6)\nsns.boxplot(heart1['Cholesterol'],color='Green')\nplt.subplot(5,2,7)\nsns.distplot(heart1['MaxHR'],color='Red')\nplt.subplot(5,2,8)\nsns.boxplot(heart1['MaxHR'],color='Red')\nplt.subplot(5,2,9)\nsns.distplot(heart1['Oldpeak'],color='Brown')\nplt.subplot(5,2,10)\nsns.boxplot(heart1['Oldpeak'],color='Brown')\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-1.png){}\n:::\n:::\n\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n#assigning values to features as X and target as y\nX=heart1.drop([\"HeartDisease\"],axis=1)\ny=heart1[\"HeartDisease\"]\n\n#Set up a standard scaler for the features\ncol_names = list(X.columns)\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n\nfor col in X.columns:\n    if not pd.api.types.is_numeric_dtype(X[col]):\n        X[col] = le.fit_transform(X[col])\n        \ns_scaler = StandardScaler()\nX_df= s_scaler.fit_transform(X)\nX_df = pd.DataFrame(X_df, columns=col_names)   \nX_df.describe().T\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Age</th>\n      <td>918.0</td>\n      <td>-1.08e-16</td>\n      <td>1.0</td>\n      <td>-2.71</td>\n      <td>-0.69</td>\n      <td>0.05</td>\n      <td>0.69</td>\n      <td>2.49</td>\n    </tr>\n    <tr>\n      <th>Sex</th>\n      <td>918.0</td>\n      <td>-7.74e-18</td>\n      <td>1.0</td>\n      <td>-1.94</td>\n      <td>0.52</td>\n      <td>0.52</td>\n      <td>0.52</td>\n      <td>0.52</td>\n    </tr>\n    <tr>\n      <th>ChestPainType</th>\n      <td>918.0</td>\n      <td>1.55e-17</td>\n      <td>1.0</td>\n      <td>-0.82</td>\n      <td>-0.82</td>\n      <td>-0.82</td>\n      <td>1.28</td>\n      <td>2.32</td>\n    </tr>\n    <tr>\n      <th>RestingBP</th>\n      <td>918.0</td>\n      <td>1.95e-16</td>\n      <td>1.0</td>\n      <td>-7.15</td>\n      <td>-0.67</td>\n      <td>-0.13</td>\n      <td>0.41</td>\n      <td>3.65</td>\n    </tr>\n    <tr>\n      <th>Cholesterol</th>\n      <td>918.0</td>\n      <td>0.00e+00</td>\n      <td>1.0</td>\n      <td>-1.82</td>\n      <td>-0.23</td>\n      <td>0.22</td>\n      <td>0.62</td>\n      <td>3.70</td>\n    </tr>\n    <tr>\n      <th>FastingBS</th>\n      <td>918.0</td>\n      <td>-3.10e-17</td>\n      <td>1.0</td>\n      <td>-0.55</td>\n      <td>-0.55</td>\n      <td>-0.55</td>\n      <td>-0.55</td>\n      <td>1.81</td>\n    </tr>\n    <tr>\n      <th>RestingECG</th>\n      <td>918.0</td>\n      <td>9.29e-17</td>\n      <td>1.0</td>\n      <td>-1.57</td>\n      <td>0.02</td>\n      <td>0.02</td>\n      <td>0.02</td>\n      <td>1.60</td>\n    </tr>\n    <tr>\n      <th>MaxHR</th>\n      <td>918.0</td>\n      <td>4.95e-16</td>\n      <td>1.0</td>\n      <td>-3.02</td>\n      <td>-0.66</td>\n      <td>0.05</td>\n      <td>0.75</td>\n      <td>2.56</td>\n    </tr>\n    <tr>\n      <th>ExerciseAngina</th>\n      <td>918.0</td>\n      <td>-3.87e-18</td>\n      <td>1.0</td>\n      <td>-0.82</td>\n      <td>-0.82</td>\n      <td>-0.82</td>\n      <td>1.21</td>\n      <td>1.21</td>\n    </tr>\n    <tr>\n      <th>Oldpeak</th>\n      <td>918.0</td>\n      <td>1.24e-16</td>\n      <td>1.0</td>\n      <td>-3.27</td>\n      <td>-0.83</td>\n      <td>-0.27</td>\n      <td>0.57</td>\n      <td>4.98</td>\n    </tr>\n    <tr>\n      <th>ST_Slope</th>\n      <td>918.0</td>\n      <td>7.74e-17</td>\n      <td>1.0</td>\n      <td>-2.24</td>\n      <td>-0.60</td>\n      <td>-0.60</td>\n      <td>1.05</td>\n      <td>1.05</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X_df,y,test_size=0.2,random_state=21)\n```\n:::\n\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train=scaler.fit_transform(X_train)\nX_test=scaler.transform(X_test)\n\nX_train = pd.DataFrame(X_train, columns=X.columns)\nX_test = pd.DataFrame(X_test, columns=X.columns)\n```\n:::\n\n\n### KNN Classifier\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nfrom sklearn.neighbors import KNeighborsClassifier\nplt.rcParams['figure.figsize'] = (8,6)\nplt.rcParams['font.size'] = 20\n\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report,f1_score\n\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\ny_pred_log = knn.predict(X_test)\n\nlog_train = round(knn.score(X_train, y_train) * 100, 2)\nlog_accuracy = round(accuracy_score(y_pred_log, y_test) * 100, 2)\nlog_f1 = round(f1_score(y_pred_log, y_test) * 100, 2)\n\nprint(\"Training Accuracy    :\",log_train,\"%\")\nprint(\"Model Accuracy Score :\",log_accuracy,\"%\")\nprint(\"\\033[1m--------------------------------------------------------\\033[0m\")\nprint(\"Classification_Report: \\n\",classification_report(y_test,y_pred_log))\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTraining Accuracy    : 88.15 %\nModel Accuracy Score : 86.96 %\n--------------------------------------------------------\nClassification_Report: \n               precision    recall  f1-score   support\n\n           0       0.87      0.80      0.84        76\n           1       0.87      0.92      0.89       108\n\n    accuracy                           0.87       184\n   macro avg       0.87      0.86      0.86       184\nweighted avg       0.87      0.87      0.87       184\n\n```\n:::\n:::\n\n\n![Confusion Matrix (src: <https://www.datacamp.com/tutorial/precision-recall-curve-tutorial>)](pr1.png){fig-alt=\"Confusion Matrix\"}\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nconfusion_matrix(y_test, y_pred_log);\n```\n:::\n\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\nknn_probs = knn.predict_proba(X_test)\nknn_probs = knn_probs[:, 1]\nfrom sklearn.metrics import roc_curve, roc_auc_score\nrf_auc = roc_auc_score(y_test, knn_probs)\nrf_fpr, rf_tpr, _ = roc_curve(y_test, knn_probs)\n```\n:::\n\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\nplt.figure(figsize=(12, 8))\nplt.plot(rf_fpr, rf_tpr, linestyle='--', label='AUC = %0.3f' % rf_auc)\n\n\nplt.title('ROC Plot')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()  \nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-22-output-1.png){}\n:::\n:::\n\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\nprecision, recall, thresholds = precision_recall_curve(y_test, knn_probs)\nplt.fill_between(recall, precision)\nplt.ylabel(\"Precision\")\nplt.xlabel(\"Recall\")\nplt.title(\"Precision-Recall curve\");\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-23-output-1.png){}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}